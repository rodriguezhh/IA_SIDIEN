{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IA_funcional.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQym4Nxb8hbjNavp2daYOi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodriguezhh/IA_SIDIEN/blob/main/IA_funcional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "CONSTRUYENDO UN MODELO SECUENCIAL"
      ],
      "metadata": {
        "id": "VqHlf9SmszKR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRXCS9j0sklB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manipulación del Dataset"
      ],
      "metadata": {
        "id": "hgWh7m7is4hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models, layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "IMAGE_SIZE = 256\n",
        "BATCH_SIZE = 64\n",
        "CHANELS = 3\n",
        "EPOCHS = 20\n",
        "\n",
        "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/Universidad/Tesis/Dataset/color\",\n",
        "    shuffle=True,\n",
        "    image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
        "    batch_size = BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "id": "BGC7jjt9s4AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtención de las clases y visualización"
      ],
      "metadata": {
        "id": "OMM2HuBus83t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = dataset.class_names\n",
        "class_names"
      ],
      "metadata": {
        "id": "bnxFZQ5Rsy8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se define los datos de entrenamiento, de validación y de testeo, mediante una Función."
      ],
      "metadata": {
        "id": "jSGpdPsJs_0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
        "\n",
        "    ds_size = len(ds)\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(shuffle_size, seed=12)\n",
        "\n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "\n",
        "    train_ds = ds.take(train_size)\n",
        "\n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "    \n",
        "    return train_ds, val_ds, test_ds"
      ],
      "metadata": {
        "id": "7gKkYfOttCC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se guardan los datos"
      ],
      "metadata": {
        "id": "udEljb57tEw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)"
      ],
      "metadata": {
        "id": "FxvKd4LatDx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_ds), len(val_ds), len(test_ds))"
      ],
      "metadata": {
        "id": "_IvZEq18tHQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resize and rescale"
      ],
      "metadata": {
        "id": "RtqdlOlgtJA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    layers.experimental.preprocessing.Rescaling(1.0/255)\n",
        "])"
      ],
      "metadata": {
        "id": "wXIdE7BztJbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation"
      ],
      "metadata": {
        "id": "TggHTxtptL--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "     ]\n",
        ")"
      ],
      "metadata": {
        "id": "Ic8nAr8ztMcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construyendo el modelo "
      ],
      "metadata": {
        "id": "REMHo6-rtPOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape = (256, 256, 3))\n",
        "\n",
        "x = resize_and_rescale(inputs)\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Conv2D(32, (3,3), activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D((2,2))(x)\n",
        "x = layers.Conv2D(16, (3,3), activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D((2,2))(x)\n",
        "x = layers.Conv2D(8, (3,3), activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D((2,2))(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "SJFSh203tQtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "r54WWhnttZvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\",#adam\n",
        " loss=\"sparse_categorical_crossentropy\",\n",
        " metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "baDW-MZotbZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_ds,\n",
        "    batch_size = BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "id": "875aUr9hteuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "K2WVKZlxtfVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images_batch, labels_batch in test_ds.take(1):\n",
        "    \n",
        "    first_image = images_batch[0].numpy().astype('uint8')\n",
        "    first_label = labels_batch[0].numpy()\n",
        "\n",
        "    print('first image to predict')\n",
        "    plt.imshow(first_image)\n",
        "    print('actual label', class_names[first_label])\n",
        "\n",
        "    batch_prediction = model.predict(images_batch)\n",
        "    print(\"predicted label: \", class_names[np.argmax(batch_prediction[0])])"
      ],
      "metadata": {
        "id": "ChXwwGY3tg-F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}